## ÏïàÎÖïÌïòÏÑ∏Ïöîüëã


Ï†ÄÏùò REPORATIGYÏóê Ïò§Ïã†Í±∏ ÌôòÏòÅÌï©ÎãàÎã§. ÎÇòÎßåÏùò ÏΩîÎìúÎ∂ÅÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ ÌäúÌÜ†Î¶¨ÏñºÏùÑ ÎßåÎì§Í≥† ÏûàÏäµÎãàÎã§. ÏïÑÏßÅ ÎßéÏù¥ Î∂ÄÏ°±Ìïú Ï†êÏù¥ ÎßéÏßÄÎßå, Í≥ÑÏÜç ÏóÖÎ°úÎìú Ìï† ÏòàÏ†ïÏûÖÎãàÎã§! 
> Îçî ÎßéÏùÄ ÌäúÌÜ†Î¶¨Ïñº Î≥¥Í∏∞ :https://github.com/seonm9119/tutorials/blob/main/README.md
---
### Tutorials
Category | Paper | Tutorial
:---: | :---: | :---:
VFM | [_An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale_](https://arxiv.org/abs/2010.11929) | [Vision Transformer](https://github.com/seonm9119/tutorials/blob/main/Vision%20Transformer.ipynb)
Machine Translation| [_Attention Is All You Need_](https://arxiv.org/abs/1706.03762)| [Transformer](https://github.com/seonm9119/tutorials/blob/main/Transformer.ipynb)
NLP|[_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding_](https://arxiv.org/abs/1810.04805)|[BERT](https://github.com/seonm9119/tutorials/blob/main/BERT.ipynb)|







